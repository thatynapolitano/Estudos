{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "81c76aea-b80b-44c8-8018-15fcfb66ae5b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<div style=\"text-align: left;\">\n",
    "\n",
    "## O que é Databricks?\n",
    "<br>\n",
    "\n",
    "- O Databricks é uma plataforma de análise de dados unificada para engenharia de dados, machine learning e ciência de dados colaborativa;\n",
    "- Workspace colaborativo;\n",
    "- Pluralidade de Linguagens com Python, R, Scala e SQL;\n",
    "- Escalabilidade;\n",
    "- Versionamento;\n",
    "- Conecta com várias outras ferramentas como Tableau, PBI, Looker...\n",
    "- Multi-cloud.\n",
    "\n",
    "<br>\n",
    "\n",
    "### ATENÇÃO: A partir de agora vamos usar a versão gratuita: Databricks Community\n",
    "\n",
    "<div/>\n",
    "\n",
    "<br>\n",
    "\n",
    "### Um pouco das múltiplas funções do Databricks em diversas arquiteturas: \n",
    "<br>\n",
    "\n",
    "<img src=\"https://learn.microsoft.com/pt-br/azure/architecture/solution-ideas/media/azure-databricks-modern-analytics-architecture.svg\"  width=\"60%\" height=\"30%\">\n",
    "\n",
    "Fonte: https://learn.microsoft.com/pt-br/azure/architecture/solution-ideas/media/azure-databricks-modern-analytics-architecture.svg\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "<img src=\"https://www.databricks.com/wp-content/uploads/2021/05/gcp-ga-blog-image-1-1024x539.png\"  width=\"60%\" height=\"30%\">\n",
    "\n",
    "Fonte: https://www.databricks.com/wp-content/uploads/2021/05/gcp-ga-blog-image-1-1024x539.png\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "## Cadastro\n",
    "\n",
    "Se inscreva no link:\n",
    "\n",
    "https://www.databricks.com/try-databricks\n",
    "\n",
    "**Na página seguinte onde ele pede para escolher uma nuvem, selecione lá embaixo \"Get started with Community Edition\"**\n",
    "\n",
    "<!-- <img src=\"imgs/databricks community.png\"  width=\"70%\" height=\"40%\"> -->\n",
    "<img src=\"/files/tables/databricks_community.png\" alt=\"drawing\"  width=\"800\"/>\n",
    "\n",
    "[Tutorial](https://www.youtube.com/watch?v=a8gsJG2lUP8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "572036c3-00c1-4300-b7c9-dc81f8ea792c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Navegando pela plataforma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0d91676b-324c-4785-a9a9-cc3009897faa",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "71be1cd3-bbfc-4f99-99c9-17f6ead66976",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Subindo e encontrando arquivo no databricks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "22375bc7-c240-4640-9bc0-f5376df9282c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "### Habilitando o DBFS File Browser\n",
    "\n",
    "Fazendo isso poderemos ver nossos arquivos do DBFS em uma aba dentro de catalog\n",
    "\n",
    "e-mail > Admin Settings > Workspace settings > Ligar o \"DBFS File Browser\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "83adb6c8-6dc6-418f-aa0f-b474fdb72c6c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### DBFS\n",
    "O [DBFS (Databricks File System)](https://docs.databricks.com/en/dbfs/index.html) é um sistema de arquivos distribuído integrado ao ambiente Databricks, projetado para armazenar e acessar dados de forma eficiente em um ambiente de computação distribuída. Assim como em um sistema de arquivos tradicional, o DBFS organiza os dados em arquivos e diretórios. Você pode criar, listar, copiar, mover e excluir arquivos e diretórios no DBFS usando comandos. Ele suporta uma variedade de tipos de dados, incluindo arquivos de texto, CSV, Parquet, JSON, AVRO e outros formatos comuns de dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "11ec479b-e740-47ab-88b1-08523ed83a27",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "### Comandos no DBFS\n",
    "Os comandos são formados utilizando-se `dbutils.fs` + o comando específico que você deseja, como por exemplo o `.help()`. Comandos disponobilizados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fc9aef37-b6a4-4619-938a-fd4fc0b8eb83",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div class = \"ansiout\"><b>dbutils.fs</b> provides utilities for working with FileSystems. Most methods in\n",
       "this package can take either a DBFS path (e.g., \"/foo\" or \"dbfs:/foo\"), or\n",
       "another FileSystem URI.\n",
       "\n",
       "For more info about a method, use <b>dbutils.fs.help(\"methodName\")</b>.\n",
       "\n",
       "In notebooks, you can also use the %fs shorthand to access DBFS. The %fs shorthand maps\n",
       "straightforwardly onto dbutils calls. For example, \"%fs head --maxBytes=10000 /file/path\"\n",
       "translates into \"dbutils.fs.head(\"/file/path\", maxBytes = 10000)\".\n",
       "    <h3>fsutils</h3><b>cp(from: String, to: String, recurse: boolean = false): boolean</b> -> Copies a file or directory, possibly across FileSystems<br /><b>head(file: String, maxBytes: int = 65536): String</b> -> Returns up to the first 'maxBytes' bytes of the given file as a String encoded in UTF-8<br /><b>ls(dir: String): Seq</b> -> Lists the contents of a directory<br /><b>mkdirs(dir: String): boolean</b> -> Creates the given directory if it does not exist, also creating any necessary parent directories<br /><b>mv(from: String, to: String, recurse: boolean = false): boolean</b> -> Moves a file or directory, possibly across FileSystems<br /><b>put(file: String, contents: String, overwrite: boolean = false): boolean</b> -> Writes the given String out to a file, encoded in UTF-8<br /><b>rm(dir: String, recurse: boolean = false): boolean</b> -> Removes a file or directory<br /><br /><h3>mount</h3><b>mount(source: String, mountPoint: String, encryptionType: String = \"\", owner: String = null, extraConfigs: Map = Map.empty[String, String]): boolean</b> -> Mounts the given source directory into DBFS at the given mount point<br /><b>mounts: Seq</b> -> Displays information about what is mounted within DBFS<br /><b>refreshMounts: boolean</b> -> Forces all machines in this cluster to refresh their mount cache, ensuring they receive the most recent information<br /><b>unmount(mountPoint: String): boolean</b> -> Deletes a DBFS mount point<br /><b>updateMount(source: String, mountPoint: String, encryptionType: String = \"\", owner: String = null, extraConfigs: Map = Map.empty[String, String]): boolean</b> -> Similar to mount(), but updates an existing mount point (if present) instead of creating a new one<br /><br /></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class = \"ansiout\"><b>dbutils.fs</b> provides utilities for working with FileSystems. Most methods in\nthis package can take either a DBFS path (e.g., \"/foo\" or \"dbfs:/foo\"), or\nanother FileSystem URI.\n\nFor more info about a method, use <b>dbutils.fs.help(\"methodName\")</b>.\n\nIn notebooks, you can also use the %fs shorthand to access DBFS. The %fs shorthand maps\nstraightforwardly onto dbutils calls. For example, \"%fs head --maxBytes=10000 /file/path\"\ntranslates into \"dbutils.fs.head(\"/file/path\", maxBytes = 10000)\".\n    <h3>fsutils</h3><b>cp(from: String, to: String, recurse: boolean = false): boolean</b> -> Copies a file or directory, possibly across FileSystems<br /><b>head(file: String, maxBytes: int = 65536): String</b> -> Returns up to the first 'maxBytes' bytes of the given file as a String encoded in UTF-8<br /><b>ls(dir: String): Seq</b> -> Lists the contents of a directory<br /><b>mkdirs(dir: String): boolean</b> -> Creates the given directory if it does not exist, also creating any necessary parent directories<br /><b>mv(from: String, to: String, recurse: boolean = false): boolean</b> -> Moves a file or directory, possibly across FileSystems<br /><b>put(file: String, contents: String, overwrite: boolean = false): boolean</b> -> Writes the given String out to a file, encoded in UTF-8<br /><b>rm(dir: String, recurse: boolean = false): boolean</b> -> Removes a file or directory<br /><br /><h3>mount</h3><b>mount(source: String, mountPoint: String, encryptionType: String = \"\", owner: String = null, extraConfigs: Map = Map.empty[String, String]): boolean</b> -> Mounts the given source directory into DBFS at the given mount point<br /><b>mounts: Seq</b> -> Displays information about what is mounted within DBFS<br /><b>refreshMounts: boolean</b> -> Forces all machines in this cluster to refresh their mount cache, ensuring they receive the most recent information<br /><b>unmount(mountPoint: String): boolean</b> -> Deletes a DBFS mount point<br /><b>updateMount(source: String, mountPoint: String, encryptionType: String = \"\", owner: String = null, extraConfigs: Map = Map.empty[String, String]): boolean</b> -> Similar to mount(), but updates an existing mount point (if present) instead of creating a new one<br /><br /></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dbutils.fs.help()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9fe03ef2-c7ec-4344-91bd-0fd5c98a6c92",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div class = \"ansiout\">/**<br /> * Copies a file or directory, possibly across FileSystems..<br /> * <br /> * Example: cp(\"/mnt/my-folder/a\", \"s3n://bucket/b\")<br /> * <br /> * @param from FileSystem URI of the source file or directory<br /> * @param to FileSystem URI of the destination file or directory<br /> * @param recurse if true, all files and directories will be recursively copied<br /> * @return true if all files were successfully copied<br /> */<br /><b>cp(from: java.lang.String, to: java.lang.String, recurse: boolean = false): boolean</b></div><br />"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class = \"ansiout\">/**<br /> * Copies a file or directory, possibly across FileSystems..<br /> * <br /> * Example: cp(\"/mnt/my-folder/a\", \"s3n://bucket/b\")<br /> * <br /> * @param from FileSystem URI of the source file or directory<br /> * @param to FileSystem URI of the destination file or directory<br /> * @param recurse if true, all files and directories will be recursively copied<br /> * @return true if all files were successfully copied<br /> */<br /><b>cp(from: java.lang.String, to: java.lang.String, recurse: boolean = false): boolean</b></div><br />",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dbutils.fs.help(\"cp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "26384734-ac06-4bef-a827-4e47374032a3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[19]: [FileInfo(path='dbfs:/FileStore/tables/fertility.csv', name='fertility.csv', size=180661, modificationTime=1710974500000)]"
     ]
    }
   ],
   "source": [
    "dbutils.fs.ls(\"/FileStore/tables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9d812a77-dfd7-4945-a368-d742046534f4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[21]: True"
     ]
    }
   ],
   "source": [
    "dbutils.fs.rm(\"/FileStore/tables/fertility.csv/\", recurse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e8af2043-188a-4563-96d1-d2230a5e920f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[32]: [FileInfo(path='dbfs:/FileStore/tables/fertility.csv', name='fertility.csv', size=180661, modificationTime=1710975891000)]"
     ]
    }
   ],
   "source": [
    "dbutils.fs.ls(\"/FileStore/tables\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "32f68fe9-0d29-405f-a773-f28b6923ea1e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "FileStore é a pasta padrão em que o Databricks irá salvar uploads de arquivos, upload de bibliotecas e gráficos gerados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fca1ead4-a62f-4a26-8d8b-73e439f2cbd9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Como abrir os arquivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "38cb1af4-4262-46dc-a6be-415b5ed1e176",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.databricks.v1+bamboolib_hint": "{\"pd.DataFrames\": [], \"version\": \"0.0.1\"}",
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-4446331874922465>:3\u001B[0m\n",
       "\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpd\u001B[39;00m \n",
       "\u001B[0;32m----> 3\u001B[0m df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_csv(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/FileStore/tables/fertility.csv/\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
       "\u001B[1;32m      4\u001B[0m df\u001B[38;5;241m.\u001B[39mhead()\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.9/site-packages/pandas/util/_decorators.py:311\u001B[0m, in \u001B[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m    305\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(args) \u001B[38;5;241m>\u001B[39m num_allow_args:\n",
       "\u001B[1;32m    306\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n",
       "\u001B[1;32m    307\u001B[0m         msg\u001B[38;5;241m.\u001B[39mformat(arguments\u001B[38;5;241m=\u001B[39marguments),\n",
       "\u001B[1;32m    308\u001B[0m         \u001B[38;5;167;01mFutureWarning\u001B[39;00m,\n",
       "\u001B[1;32m    309\u001B[0m         stacklevel\u001B[38;5;241m=\u001B[39mstacklevel,\n",
       "\u001B[1;32m    310\u001B[0m     )\n",
       "\u001B[0;32m--> 311\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.9/site-packages/pandas/io/parsers/readers.py:680\u001B[0m, in \u001B[0;36mread_csv\u001B[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001B[0m\n",
       "\u001B[1;32m    665\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n",
       "\u001B[1;32m    666\u001B[0m     dialect,\n",
       "\u001B[1;32m    667\u001B[0m     delimiter,\n",
       "\u001B[0;32m   (...)\u001B[0m\n",
       "\u001B[1;32m    676\u001B[0m     defaults\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdelimiter\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m,\u001B[39m\u001B[38;5;124m\"\u001B[39m},\n",
       "\u001B[1;32m    677\u001B[0m )\n",
       "\u001B[1;32m    678\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n",
       "\u001B[0;32m--> 680\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.9/site-packages/pandas/io/parsers/readers.py:575\u001B[0m, in \u001B[0;36m_read\u001B[0;34m(filepath_or_buffer, kwds)\u001B[0m\n",
       "\u001B[1;32m    572\u001B[0m _validate_names(kwds\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnames\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n",
       "\u001B[1;32m    574\u001B[0m \u001B[38;5;66;03m# Create the parser.\u001B[39;00m\n",
       "\u001B[0;32m--> 575\u001B[0m parser \u001B[38;5;241m=\u001B[39m \u001B[43mTextFileReader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    577\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m chunksize \u001B[38;5;129;01mor\u001B[39;00m iterator:\n",
       "\u001B[1;32m    578\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.9/site-packages/pandas/io/parsers/readers.py:933\u001B[0m, in \u001B[0;36mTextFileReader.__init__\u001B[0;34m(self, f, engine, **kwds)\u001B[0m\n",
       "\u001B[1;32m    930\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m kwds[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
       "\u001B[1;32m    932\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles: IOHandles \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
       "\u001B[0;32m--> 933\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_engine\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mengine\u001B[49m\u001B[43m)\u001B[49m\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1217\u001B[0m, in \u001B[0;36mTextFileReader._make_engine\u001B[0;34m(self, f, engine)\u001B[0m\n",
       "\u001B[1;32m   1213\u001B[0m     mode \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrb\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m   1214\u001B[0m \u001B[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001B[39;00m\n",
       "\u001B[1;32m   1215\u001B[0m \u001B[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001B[39;00m\n",
       "\u001B[1;32m   1216\u001B[0m \u001B[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001B[39;00m\n",
       "\u001B[0;32m-> 1217\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;241m=\u001B[39m \u001B[43mget_handle\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[call-overload]\u001B[39;49;00m\n",
       "\u001B[1;32m   1218\u001B[0m \u001B[43m    \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m   1219\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m   1220\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m   1221\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcompression\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m   1222\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmemory_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmemory_map\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m   1223\u001B[0m \u001B[43m    \u001B[49m\u001B[43mis_text\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_text\u001B[49m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m   1224\u001B[0m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding_errors\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstrict\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m   1225\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstorage_options\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m   1226\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m   1227\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
       "\u001B[1;32m   1228\u001B[0m f \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles\u001B[38;5;241m.\u001B[39mhandle\n",
       "\n",
       "File \u001B[0;32m/databricks/python/lib/python3.9/site-packages/pandas/io/common.py:789\u001B[0m, in \u001B[0;36mget_handle\u001B[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n",
       "\u001B[1;32m    784\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(handle, \u001B[38;5;28mstr\u001B[39m):\n",
       "\u001B[1;32m    785\u001B[0m     \u001B[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001B[39;00m\n",
       "\u001B[1;32m    786\u001B[0m     \u001B[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001B[39;00m\n",
       "\u001B[1;32m    787\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mencoding \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mmode:\n",
       "\u001B[1;32m    788\u001B[0m         \u001B[38;5;66;03m# Encoding\u001B[39;00m\n",
       "\u001B[0;32m--> 789\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\n",
       "\u001B[1;32m    790\u001B[0m \u001B[43m            \u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m    791\u001B[0m \u001B[43m            \u001B[49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m    792\u001B[0m \u001B[43m            \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m    793\u001B[0m \u001B[43m            \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m    794\u001B[0m \u001B[43m            \u001B[49m\u001B[43mnewline\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n",
       "\u001B[1;32m    795\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    796\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[1;32m    797\u001B[0m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n",
       "\u001B[1;32m    798\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(handle, ioargs\u001B[38;5;241m.\u001B[39mmode)\n",
       "\n",
       "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '/FileStore/tables/fertility.csv/'"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)\nFile \u001B[0;32m<command-4446331874922465>:3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpd\u001B[39;00m \n\u001B[0;32m----> 3\u001B[0m df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_csv(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/FileStore/tables/fertility.csv/\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      4\u001B[0m df\u001B[38;5;241m.\u001B[39mhead()\n\nFile \u001B[0;32m/databricks/python/lib/python3.9/site-packages/pandas/util/_decorators.py:311\u001B[0m, in \u001B[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    305\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(args) \u001B[38;5;241m>\u001B[39m num_allow_args:\n\u001B[1;32m    306\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[1;32m    307\u001B[0m         msg\u001B[38;5;241m.\u001B[39mformat(arguments\u001B[38;5;241m=\u001B[39marguments),\n\u001B[1;32m    308\u001B[0m         \u001B[38;5;167;01mFutureWarning\u001B[39;00m,\n\u001B[1;32m    309\u001B[0m         stacklevel\u001B[38;5;241m=\u001B[39mstacklevel,\n\u001B[1;32m    310\u001B[0m     )\n\u001B[0;32m--> 311\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\nFile \u001B[0;32m/databricks/python/lib/python3.9/site-packages/pandas/io/parsers/readers.py:680\u001B[0m, in \u001B[0;36mread_csv\u001B[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001B[0m\n\u001B[1;32m    665\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[1;32m    666\u001B[0m     dialect,\n\u001B[1;32m    667\u001B[0m     delimiter,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    676\u001B[0m     defaults\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdelimiter\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m,\u001B[39m\u001B[38;5;124m\"\u001B[39m},\n\u001B[1;32m    677\u001B[0m )\n\u001B[1;32m    678\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[0;32m--> 680\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\nFile \u001B[0;32m/databricks/python/lib/python3.9/site-packages/pandas/io/parsers/readers.py:575\u001B[0m, in \u001B[0;36m_read\u001B[0;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[1;32m    572\u001B[0m _validate_names(kwds\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnames\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[1;32m    574\u001B[0m \u001B[38;5;66;03m# Create the parser.\u001B[39;00m\n\u001B[0;32m--> 575\u001B[0m parser \u001B[38;5;241m=\u001B[39m \u001B[43mTextFileReader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    577\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m chunksize \u001B[38;5;129;01mor\u001B[39;00m iterator:\n\u001B[1;32m    578\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n\nFile \u001B[0;32m/databricks/python/lib/python3.9/site-packages/pandas/io/parsers/readers.py:933\u001B[0m, in \u001B[0;36mTextFileReader.__init__\u001B[0;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[1;32m    930\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m kwds[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m    932\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles: IOHandles \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m--> 933\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_engine\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mengine\u001B[49m\u001B[43m)\u001B[49m\n\nFile \u001B[0;32m/databricks/python/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1217\u001B[0m, in \u001B[0;36mTextFileReader._make_engine\u001B[0;34m(self, f, engine)\u001B[0m\n\u001B[1;32m   1213\u001B[0m     mode \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrb\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1214\u001B[0m \u001B[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001B[39;00m\n\u001B[1;32m   1215\u001B[0m \u001B[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001B[39;00m\n\u001B[1;32m   1216\u001B[0m \u001B[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001B[39;00m\n\u001B[0;32m-> 1217\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;241m=\u001B[39m \u001B[43mget_handle\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[call-overload]\u001B[39;49;00m\n\u001B[1;32m   1218\u001B[0m \u001B[43m    \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1219\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1220\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1221\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcompression\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1222\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmemory_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmemory_map\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1223\u001B[0m \u001B[43m    \u001B[49m\u001B[43mis_text\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_text\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1224\u001B[0m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding_errors\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstrict\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1225\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstorage_options\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1226\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1227\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1228\u001B[0m f \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles\u001B[38;5;241m.\u001B[39mhandle\n\nFile \u001B[0;32m/databricks/python/lib/python3.9/site-packages/pandas/io/common.py:789\u001B[0m, in \u001B[0;36mget_handle\u001B[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[1;32m    784\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(handle, \u001B[38;5;28mstr\u001B[39m):\n\u001B[1;32m    785\u001B[0m     \u001B[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001B[39;00m\n\u001B[1;32m    786\u001B[0m     \u001B[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001B[39;00m\n\u001B[1;32m    787\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mencoding \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mmode:\n\u001B[1;32m    788\u001B[0m         \u001B[38;5;66;03m# Encoding\u001B[39;00m\n\u001B[0;32m--> 789\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[1;32m    790\u001B[0m \u001B[43m            \u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    791\u001B[0m \u001B[43m            \u001B[49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    792\u001B[0m \u001B[43m            \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    793\u001B[0m \u001B[43m            \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    794\u001B[0m \u001B[43m            \u001B[49m\u001B[43mnewline\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    795\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    796\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    797\u001B[0m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[1;32m    798\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(handle, ioargs\u001B[38;5;241m.\u001B[39mmode)\n\n\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '/FileStore/tables/fertility.csv/'",
       "errorSummary": "<span class='ansi-red-fg'>FileNotFoundError</span>: [Errno 2] No such file or directory: '/FileStore/tables/fertility.csv/'",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df = pd.read_csv(\"/FileStore/tables/fertility.csv/\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e167ed4f-25ae-4e25-ab03-85f90dd6f373",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "O Pandas opera localmente e não pode acessar arquivos diretamente do DBFS. Para isso usamos PySpark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "00fef577-43d0-4b89-8069-372584f29bb6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "### Apache Spark\n",
    "Spark é um framework de código aberto para executar aplicativos de análise de dados em larga escala em clusters. Ele pode lidar tanto com cargas de trabalho de análise em lote quanto em tempo real, e também com o processamento de dados paralelizado.\n",
    "\n",
    "<img src=\"http://crossroadelf.com/assets/img/spark-crossroadelf.jpg\" width=\"900\" text=\"http://crossroadelf.com/spark.php\">\n",
    "\n",
    "- Processamento de dados em lote: O Spark é frequentemente usado para processar grandes volumes de dados em lote de forma eficiente. Ele pode lidar com cargas de trabalho de processamento em lote de alto volume, como extração, transformação e carga (ETL), processamento de logs, processamento de dados de séries temporais e muito mais.\n",
    "\n",
    "- Análise de dados em tempo real: O Spark oferece suporte ao processamento de dados em tempo real por meio de sua biblioteca Spark Streaming. Ele pode processar e analisar streams contínuos de dados em tempo real, permitindo a detecção de padrões em tempo real, processamento de eventos em tempo real e análises de fluxo de dados em tempo real.\n",
    "\n",
    "- Machine learning: O Spark fornece uma biblioteca chamada MLlib, que oferece uma ampla gama de algoritmos e ferramentas para aprendizado de máquina e mineração de dados. Ele pode ser usado para treinar modelos de aprendizado de máquina em conjuntos de dados grandes e realizar análises preditivas, classificação, clustering e muito mais.\n",
    "\n",
    "- Processamento de grafos: O Spark inclui a biblioteca GraphX, que permite representar e processar grafos em grande escala de forma distribuída. Isso é útil para análises de redes sociais, análises de rede, detecção de comunidades, análises de fluxo de dados de rede e muito mais.\n",
    "\n",
    "- Análise de dados: O SparkSQL permite executar consultas SQL em grandes conjuntos de dados distribuídos. Isso é útil para analisar dados estruturados e semi-estruturados em larga escala, realizar agregações, filtragem, junções e outras operações de manipulação de dados usando uma interface SQL familiar. Além disso, também temos outras liguagens de programação em que é possível usar o spark.\n",
    "\n",
    "<br><br>\n",
    "\n",
    "<img src=\"https://www.researchgate.net/publication/372489277/figure/fig1/AS:11431281176750222@1690255277932/The-Apache-Spark-layered-architecture-The-colors-are-used-only-to-distinguish-the.png\" text=\"https://www.researchgate.net/figure/The-Apache-Spark-layered-architecture-The-colors-are-used-only-to-distinguish-the_fig1_372489277\" width=700>\n",
    "\n",
    "Exemplo da arquitetura em camadas do Apache Spark. De baixo para cima, a primeira camada mostra algumas das opções de armazenamento mais comuns usadas por aplicativos Apache Spark para armazenar e recuperar dados externos: o sistema de arquivos local, o sistema de arquivos Apache Hadoop HDFS, o sistema de arquivos S3, Ceph e o GCS. A segunda camada mostra os motores de agendamento que suportam a capacidade de executar cálculos Apache Spark nos nós de um sistema distribuído: Apache Hadoop YARN, Mesos, Kubernetes e o gerenciador de cluster integrado ao Apache Spark. A opção Kubernetes foi incluída mesmo faltando algumas características relevantes, como gerenciamento de recursos e filas de trabalhos, porque é frequentemente usada no mundo real. A terceira camada mostra o núcleo do framework Apache Spark. A quarta camada mostra as bibliotecas padrão integradas ao Apache Spark: SparkSQL, útil para consultar conjuntos de dados muito grandes usando um dialeto da linguagem SQL; MLlib, uma biblioteca de algoritmos e métodos de aprendizado de máquina prontos para uso; GraphX, uma biblioteca para representar e processar grafos muito grandes usando uma abordagem distribuída; e Spark Streaming, uma biblioteca para processamento distribuído de dados em tempo real. A camada superior lista as linguagens de programação que podem ser usadas para escrever aplicativos Apache Spark.\n",
    "\n",
    "<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8f8b14a4-b917-482b-b915-38dd6dc07a8a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "<img src=\"https://editor.analyticsvidhya.com/uploads/210532.jpg\" text=\"https://www.analyticsvidhya.com/blog/2022/04/getting-started-with-pyspark-using-python/\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2ece21e0-3b1f-497b-ad9f-1e6068442525",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country Name</th>\n",
       "      <th>Country Code</th>\n",
       "      <th>Indicator Name</th>\n",
       "      <th>Indicator Code</th>\n",
       "      <th>1960</th>\n",
       "      <th>1961</th>\n",
       "      <th>1962</th>\n",
       "      <th>1963</th>\n",
       "      <th>1964</th>\n",
       "      <th>1965</th>\n",
       "      <th>1966</th>\n",
       "      <th>1967</th>\n",
       "      <th>1968</th>\n",
       "      <th>1969</th>\n",
       "      <th>1970</th>\n",
       "      <th>1971</th>\n",
       "      <th>1972</th>\n",
       "      <th>1973</th>\n",
       "      <th>1974</th>\n",
       "      <th>1975</th>\n",
       "      <th>1976</th>\n",
       "      <th>1977</th>\n",
       "      <th>1978</th>\n",
       "      <th>1979</th>\n",
       "      <th>1980</th>\n",
       "      <th>1981</th>\n",
       "      <th>1982</th>\n",
       "      <th>1983</th>\n",
       "      <th>1984</th>\n",
       "      <th>1985</th>\n",
       "      <th>1986</th>\n",
       "      <th>1987</th>\n",
       "      <th>1988</th>\n",
       "      <th>1989</th>\n",
       "      <th>1990</th>\n",
       "      <th>1991</th>\n",
       "      <th>1992</th>\n",
       "      <th>1993</th>\n",
       "      <th>1994</th>\n",
       "      <th>1995</th>\n",
       "      <th>1996</th>\n",
       "      <th>1997</th>\n",
       "      <th>1998</th>\n",
       "      <th>1999</th>\n",
       "      <th>2000</th>\n",
       "      <th>2001</th>\n",
       "      <th>2002</th>\n",
       "      <th>2003</th>\n",
       "      <th>2004</th>\n",
       "      <th>2005</th>\n",
       "      <th>2006</th>\n",
       "      <th>2007</th>\n",
       "      <th>2008</th>\n",
       "      <th>2009</th>\n",
       "      <th>2010</th>\n",
       "      <th>2011</th>\n",
       "      <th>2012</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "      <th>2020</th>\n",
       "      <th>2021</th>\n",
       "      <th>2022</th>\n",
       "      <th>_c67</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aruba</td>\n",
       "      <td>ABW</td>\n",
       "      <td>Fertility rate, total (births per woman)</td>\n",
       "      <td>SP.DYN.TFRT.IN</td>\n",
       "      <td>4.820000</td>\n",
       "      <td>4.655000</td>\n",
       "      <td>4.471000</td>\n",
       "      <td>4.271000</td>\n",
       "      <td>4.059000</td>\n",
       "      <td>3.842000</td>\n",
       "      <td>3.625000</td>\n",
       "      <td>3.417000</td>\n",
       "      <td>3.226000</td>\n",
       "      <td>3.054000</td>\n",
       "      <td>2.908000</td>\n",
       "      <td>2.788000</td>\n",
       "      <td>2.691000</td>\n",
       "      <td>2.613000</td>\n",
       "      <td>2.552000</td>\n",
       "      <td>2.506000</td>\n",
       "      <td>2.472000</td>\n",
       "      <td>2.446000</td>\n",
       "      <td>2.425000</td>\n",
       "      <td>2.408000</td>\n",
       "      <td>2.392000</td>\n",
       "      <td>2.377000</td>\n",
       "      <td>2.364000</td>\n",
       "      <td>2.353000</td>\n",
       "      <td>2.342000</td>\n",
       "      <td>2.332000</td>\n",
       "      <td>2.320000</td>\n",
       "      <td>2.307000</td>\n",
       "      <td>2.291000</td>\n",
       "      <td>2.272000</td>\n",
       "      <td>2.303000</td>\n",
       "      <td>2.314000</td>\n",
       "      <td>2.277000</td>\n",
       "      <td>2.226000</td>\n",
       "      <td>2.125000</td>\n",
       "      <td>2.190000</td>\n",
       "      <td>2.153000</td>\n",
       "      <td>2.144000</td>\n",
       "      <td>1.957000</td>\n",
       "      <td>1.869000</td>\n",
       "      <td>1.904000</td>\n",
       "      <td>1.833000</td>\n",
       "      <td>1.763000</td>\n",
       "      <td>1.747000</td>\n",
       "      <td>1.683000</td>\n",
       "      <td>1.777000</td>\n",
       "      <td>1.909000</td>\n",
       "      <td>1.928000</td>\n",
       "      <td>1.935000</td>\n",
       "      <td>1.919000</td>\n",
       "      <td>1.941000</td>\n",
       "      <td>1.962000</td>\n",
       "      <td>2.028000</td>\n",
       "      <td>2.11700</td>\n",
       "      <td>2.148000</td>\n",
       "      <td>1.972000</td>\n",
       "      <td>1.953000</td>\n",
       "      <td>1.839000</td>\n",
       "      <td>1.587000</td>\n",
       "      <td>1.486000</td>\n",
       "      <td>1.325000</td>\n",
       "      <td>1.180000</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Africa Eastern and Southern</td>\n",
       "      <td>AFE</td>\n",
       "      <td>Fertility rate, total (births per woman)</td>\n",
       "      <td>SP.DYN.TFRT.IN</td>\n",
       "      <td>6.724125</td>\n",
       "      <td>6.742752</td>\n",
       "      <td>6.762930</td>\n",
       "      <td>6.778712</td>\n",
       "      <td>6.788420</td>\n",
       "      <td>6.800322</td>\n",
       "      <td>6.810571</td>\n",
       "      <td>6.818612</td>\n",
       "      <td>6.828560</td>\n",
       "      <td>6.834418</td>\n",
       "      <td>6.838304</td>\n",
       "      <td>6.844988</td>\n",
       "      <td>6.841097</td>\n",
       "      <td>6.832243</td>\n",
       "      <td>6.820429</td>\n",
       "      <td>6.805172</td>\n",
       "      <td>6.785995</td>\n",
       "      <td>6.767943</td>\n",
       "      <td>6.750403</td>\n",
       "      <td>6.730276</td>\n",
       "      <td>6.704623</td>\n",
       "      <td>6.672362</td>\n",
       "      <td>6.638489</td>\n",
       "      <td>6.604408</td>\n",
       "      <td>6.565696</td>\n",
       "      <td>6.514957</td>\n",
       "      <td>6.464310</td>\n",
       "      <td>6.419489</td>\n",
       "      <td>6.344942</td>\n",
       "      <td>6.263838</td>\n",
       "      <td>6.166608</td>\n",
       "      <td>6.099858</td>\n",
       "      <td>6.028339</td>\n",
       "      <td>5.958973</td>\n",
       "      <td>5.897442</td>\n",
       "      <td>5.844759</td>\n",
       "      <td>5.774864</td>\n",
       "      <td>5.701466</td>\n",
       "      <td>5.643222</td>\n",
       "      <td>5.586988</td>\n",
       "      <td>5.523553</td>\n",
       "      <td>5.481624</td>\n",
       "      <td>5.430475</td>\n",
       "      <td>5.380846</td>\n",
       "      <td>5.343159</td>\n",
       "      <td>5.307120</td>\n",
       "      <td>5.267691</td>\n",
       "      <td>5.224575</td>\n",
       "      <td>5.192592</td>\n",
       "      <td>5.115156</td>\n",
       "      <td>5.040797</td>\n",
       "      <td>4.962611</td>\n",
       "      <td>4.879018</td>\n",
       "      <td>4.80882</td>\n",
       "      <td>4.739861</td>\n",
       "      <td>4.677618</td>\n",
       "      <td>4.615670</td>\n",
       "      <td>4.570409</td>\n",
       "      <td>4.527705</td>\n",
       "      <td>4.482898</td>\n",
       "      <td>4.416900</td>\n",
       "      <td>4.354709</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>AFG</td>\n",
       "      <td>Fertility rate, total (births per woman)</td>\n",
       "      <td>SP.DYN.TFRT.IN</td>\n",
       "      <td>7.282000</td>\n",
       "      <td>7.284000</td>\n",
       "      <td>7.292000</td>\n",
       "      <td>7.302000</td>\n",
       "      <td>7.304000</td>\n",
       "      <td>7.305000</td>\n",
       "      <td>7.320000</td>\n",
       "      <td>7.339000</td>\n",
       "      <td>7.363000</td>\n",
       "      <td>7.389000</td>\n",
       "      <td>7.400000</td>\n",
       "      <td>7.432000</td>\n",
       "      <td>7.453000</td>\n",
       "      <td>7.487000</td>\n",
       "      <td>7.526000</td>\n",
       "      <td>7.542000</td>\n",
       "      <td>7.561000</td>\n",
       "      <td>7.591000</td>\n",
       "      <td>7.599000</td>\n",
       "      <td>7.612000</td>\n",
       "      <td>7.588000</td>\n",
       "      <td>7.568000</td>\n",
       "      <td>7.553000</td>\n",
       "      <td>7.537000</td>\n",
       "      <td>7.513000</td>\n",
       "      <td>7.517000</td>\n",
       "      <td>7.519000</td>\n",
       "      <td>7.526000</td>\n",
       "      <td>7.531000</td>\n",
       "      <td>7.533000</td>\n",
       "      <td>7.565000</td>\n",
       "      <td>7.606000</td>\n",
       "      <td>7.665000</td>\n",
       "      <td>7.719000</td>\n",
       "      <td>7.717000</td>\n",
       "      <td>7.712000</td>\n",
       "      <td>7.709000</td>\n",
       "      <td>7.667000</td>\n",
       "      <td>7.642000</td>\n",
       "      <td>7.599000</td>\n",
       "      <td>7.534000</td>\n",
       "      <td>7.446000</td>\n",
       "      <td>7.339000</td>\n",
       "      <td>7.220000</td>\n",
       "      <td>7.069000</td>\n",
       "      <td>6.905000</td>\n",
       "      <td>6.722000</td>\n",
       "      <td>6.530000</td>\n",
       "      <td>6.376000</td>\n",
       "      <td>6.235000</td>\n",
       "      <td>6.099000</td>\n",
       "      <td>5.958000</td>\n",
       "      <td>5.830000</td>\n",
       "      <td>5.69600</td>\n",
       "      <td>5.560000</td>\n",
       "      <td>5.405000</td>\n",
       "      <td>5.262000</td>\n",
       "      <td>5.129000</td>\n",
       "      <td>5.002000</td>\n",
       "      <td>4.870000</td>\n",
       "      <td>4.750000</td>\n",
       "      <td>4.643000</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Africa Western and Central</td>\n",
       "      <td>AFW</td>\n",
       "      <td>Fertility rate, total (births per woman)</td>\n",
       "      <td>SP.DYN.TFRT.IN</td>\n",
       "      <td>6.458448</td>\n",
       "      <td>6.471518</td>\n",
       "      <td>6.491826</td>\n",
       "      <td>6.506088</td>\n",
       "      <td>6.525355</td>\n",
       "      <td>6.541102</td>\n",
       "      <td>6.564967</td>\n",
       "      <td>6.589806</td>\n",
       "      <td>6.612775</td>\n",
       "      <td>6.635181</td>\n",
       "      <td>6.657122</td>\n",
       "      <td>6.697724</td>\n",
       "      <td>6.733536</td>\n",
       "      <td>6.764288</td>\n",
       "      <td>6.803394</td>\n",
       "      <td>6.840536</td>\n",
       "      <td>6.861314</td>\n",
       "      <td>6.896182</td>\n",
       "      <td>6.923034</td>\n",
       "      <td>6.914118</td>\n",
       "      <td>6.896995</td>\n",
       "      <td>6.880294</td>\n",
       "      <td>6.855267</td>\n",
       "      <td>6.830516</td>\n",
       "      <td>6.780680</td>\n",
       "      <td>6.726142</td>\n",
       "      <td>6.683321</td>\n",
       "      <td>6.636463</td>\n",
       "      <td>6.599015</td>\n",
       "      <td>6.565149</td>\n",
       "      <td>6.518278</td>\n",
       "      <td>6.470556</td>\n",
       "      <td>6.418304</td>\n",
       "      <td>6.362464</td>\n",
       "      <td>6.296237</td>\n",
       "      <td>6.235698</td>\n",
       "      <td>6.170299</td>\n",
       "      <td>6.101633</td>\n",
       "      <td>6.043931</td>\n",
       "      <td>6.029579</td>\n",
       "      <td>6.023179</td>\n",
       "      <td>5.995955</td>\n",
       "      <td>5.967267</td>\n",
       "      <td>5.931999</td>\n",
       "      <td>5.887567</td>\n",
       "      <td>5.864604</td>\n",
       "      <td>5.845380</td>\n",
       "      <td>5.815814</td>\n",
       "      <td>5.788525</td>\n",
       "      <td>5.749043</td>\n",
       "      <td>5.699552</td>\n",
       "      <td>5.645672</td>\n",
       "      <td>5.580892</td>\n",
       "      <td>5.50635</td>\n",
       "      <td>5.437493</td>\n",
       "      <td>5.385059</td>\n",
       "      <td>5.328709</td>\n",
       "      <td>5.255345</td>\n",
       "      <td>5.186319</td>\n",
       "      <td>5.118932</td>\n",
       "      <td>5.049329</td>\n",
       "      <td>4.978662</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Angola</td>\n",
       "      <td>AGO</td>\n",
       "      <td>Fertility rate, total (births per woman)</td>\n",
       "      <td>SP.DYN.TFRT.IN</td>\n",
       "      <td>6.708000</td>\n",
       "      <td>6.790000</td>\n",
       "      <td>6.872000</td>\n",
       "      <td>6.954000</td>\n",
       "      <td>7.036000</td>\n",
       "      <td>7.116000</td>\n",
       "      <td>7.194000</td>\n",
       "      <td>7.267000</td>\n",
       "      <td>7.332000</td>\n",
       "      <td>7.388000</td>\n",
       "      <td>7.434000</td>\n",
       "      <td>7.467000</td>\n",
       "      <td>7.488000</td>\n",
       "      <td>7.498000</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>7.494000</td>\n",
       "      <td>7.485000</td>\n",
       "      <td>7.475000</td>\n",
       "      <td>7.467000</td>\n",
       "      <td>7.461000</td>\n",
       "      <td>7.459000</td>\n",
       "      <td>7.459000</td>\n",
       "      <td>7.461000</td>\n",
       "      <td>7.462000</td>\n",
       "      <td>7.459000</td>\n",
       "      <td>7.451000</td>\n",
       "      <td>7.435000</td>\n",
       "      <td>7.409000</td>\n",
       "      <td>7.373000</td>\n",
       "      <td>7.328000</td>\n",
       "      <td>7.272000</td>\n",
       "      <td>7.208000</td>\n",
       "      <td>7.138000</td>\n",
       "      <td>7.065000</td>\n",
       "      <td>6.990000</td>\n",
       "      <td>6.918000</td>\n",
       "      <td>6.851000</td>\n",
       "      <td>6.789000</td>\n",
       "      <td>6.732000</td>\n",
       "      <td>6.683000</td>\n",
       "      <td>6.639000</td>\n",
       "      <td>6.601000</td>\n",
       "      <td>6.567000</td>\n",
       "      <td>6.533000</td>\n",
       "      <td>6.499000</td>\n",
       "      <td>6.461000</td>\n",
       "      <td>6.419000</td>\n",
       "      <td>6.372000</td>\n",
       "      <td>6.320000</td>\n",
       "      <td>6.260000</td>\n",
       "      <td>6.194000</td>\n",
       "      <td>6.120000</td>\n",
       "      <td>6.039000</td>\n",
       "      <td>5.95300</td>\n",
       "      <td>5.864000</td>\n",
       "      <td>5.774000</td>\n",
       "      <td>5.686000</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>5.519000</td>\n",
       "      <td>5.442000</td>\n",
       "      <td>5.371000</td>\n",
       "      <td>5.304000</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Country Name</th>\n      <th>Country Code</th>\n      <th>Indicator Name</th>\n      <th>Indicator Code</th>\n      <th>1960</th>\n      <th>1961</th>\n      <th>1962</th>\n      <th>1963</th>\n      <th>1964</th>\n      <th>1965</th>\n      <th>1966</th>\n      <th>1967</th>\n      <th>1968</th>\n      <th>1969</th>\n      <th>1970</th>\n      <th>1971</th>\n      <th>1972</th>\n      <th>1973</th>\n      <th>1974</th>\n      <th>1975</th>\n      <th>1976</th>\n      <th>1977</th>\n      <th>1978</th>\n      <th>1979</th>\n      <th>1980</th>\n      <th>1981</th>\n      <th>1982</th>\n      <th>1983</th>\n      <th>1984</th>\n      <th>1985</th>\n      <th>1986</th>\n      <th>1987</th>\n      <th>1988</th>\n      <th>1989</th>\n      <th>1990</th>\n      <th>1991</th>\n      <th>1992</th>\n      <th>1993</th>\n      <th>1994</th>\n      <th>1995</th>\n      <th>1996</th>\n      <th>1997</th>\n      <th>1998</th>\n      <th>1999</th>\n      <th>2000</th>\n      <th>2001</th>\n      <th>2002</th>\n      <th>2003</th>\n      <th>2004</th>\n      <th>2005</th>\n      <th>2006</th>\n      <th>2007</th>\n      <th>2008</th>\n      <th>2009</th>\n      <th>2010</th>\n      <th>2011</th>\n      <th>2012</th>\n      <th>2013</th>\n      <th>2014</th>\n      <th>2015</th>\n      <th>2016</th>\n      <th>2017</th>\n      <th>2018</th>\n      <th>2019</th>\n      <th>2020</th>\n      <th>2021</th>\n      <th>2022</th>\n      <th>_c67</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Aruba</td>\n      <td>ABW</td>\n      <td>Fertility rate, total (births per woman)</td>\n      <td>SP.DYN.TFRT.IN</td>\n      <td>4.820000</td>\n      <td>4.655000</td>\n      <td>4.471000</td>\n      <td>4.271000</td>\n      <td>4.059000</td>\n      <td>3.842000</td>\n      <td>3.625000</td>\n      <td>3.417000</td>\n      <td>3.226000</td>\n      <td>3.054000</td>\n      <td>2.908000</td>\n      <td>2.788000</td>\n      <td>2.691000</td>\n      <td>2.613000</td>\n      <td>2.552000</td>\n      <td>2.506000</td>\n      <td>2.472000</td>\n      <td>2.446000</td>\n      <td>2.425000</td>\n      <td>2.408000</td>\n      <td>2.392000</td>\n      <td>2.377000</td>\n      <td>2.364000</td>\n      <td>2.353000</td>\n      <td>2.342000</td>\n      <td>2.332000</td>\n      <td>2.320000</td>\n      <td>2.307000</td>\n      <td>2.291000</td>\n      <td>2.272000</td>\n      <td>2.303000</td>\n      <td>2.314000</td>\n      <td>2.277000</td>\n      <td>2.226000</td>\n      <td>2.125000</td>\n      <td>2.190000</td>\n      <td>2.153000</td>\n      <td>2.144000</td>\n      <td>1.957000</td>\n      <td>1.869000</td>\n      <td>1.904000</td>\n      <td>1.833000</td>\n      <td>1.763000</td>\n      <td>1.747000</td>\n      <td>1.683000</td>\n      <td>1.777000</td>\n      <td>1.909000</td>\n      <td>1.928000</td>\n      <td>1.935000</td>\n      <td>1.919000</td>\n      <td>1.941000</td>\n      <td>1.962000</td>\n      <td>2.028000</td>\n      <td>2.11700</td>\n      <td>2.148000</td>\n      <td>1.972000</td>\n      <td>1.953000</td>\n      <td>1.839000</td>\n      <td>1.587000</td>\n      <td>1.486000</td>\n      <td>1.325000</td>\n      <td>1.180000</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Africa Eastern and Southern</td>\n      <td>AFE</td>\n      <td>Fertility rate, total (births per woman)</td>\n      <td>SP.DYN.TFRT.IN</td>\n      <td>6.724125</td>\n      <td>6.742752</td>\n      <td>6.762930</td>\n      <td>6.778712</td>\n      <td>6.788420</td>\n      <td>6.800322</td>\n      <td>6.810571</td>\n      <td>6.818612</td>\n      <td>6.828560</td>\n      <td>6.834418</td>\n      <td>6.838304</td>\n      <td>6.844988</td>\n      <td>6.841097</td>\n      <td>6.832243</td>\n      <td>6.820429</td>\n      <td>6.805172</td>\n      <td>6.785995</td>\n      <td>6.767943</td>\n      <td>6.750403</td>\n      <td>6.730276</td>\n      <td>6.704623</td>\n      <td>6.672362</td>\n      <td>6.638489</td>\n      <td>6.604408</td>\n      <td>6.565696</td>\n      <td>6.514957</td>\n      <td>6.464310</td>\n      <td>6.419489</td>\n      <td>6.344942</td>\n      <td>6.263838</td>\n      <td>6.166608</td>\n      <td>6.099858</td>\n      <td>6.028339</td>\n      <td>5.958973</td>\n      <td>5.897442</td>\n      <td>5.844759</td>\n      <td>5.774864</td>\n      <td>5.701466</td>\n      <td>5.643222</td>\n      <td>5.586988</td>\n      <td>5.523553</td>\n      <td>5.481624</td>\n      <td>5.430475</td>\n      <td>5.380846</td>\n      <td>5.343159</td>\n      <td>5.307120</td>\n      <td>5.267691</td>\n      <td>5.224575</td>\n      <td>5.192592</td>\n      <td>5.115156</td>\n      <td>5.040797</td>\n      <td>4.962611</td>\n      <td>4.879018</td>\n      <td>4.80882</td>\n      <td>4.739861</td>\n      <td>4.677618</td>\n      <td>4.615670</td>\n      <td>4.570409</td>\n      <td>4.527705</td>\n      <td>4.482898</td>\n      <td>4.416900</td>\n      <td>4.354709</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Afghanistan</td>\n      <td>AFG</td>\n      <td>Fertility rate, total (births per woman)</td>\n      <td>SP.DYN.TFRT.IN</td>\n      <td>7.282000</td>\n      <td>7.284000</td>\n      <td>7.292000</td>\n      <td>7.302000</td>\n      <td>7.304000</td>\n      <td>7.305000</td>\n      <td>7.320000</td>\n      <td>7.339000</td>\n      <td>7.363000</td>\n      <td>7.389000</td>\n      <td>7.400000</td>\n      <td>7.432000</td>\n      <td>7.453000</td>\n      <td>7.487000</td>\n      <td>7.526000</td>\n      <td>7.542000</td>\n      <td>7.561000</td>\n      <td>7.591000</td>\n      <td>7.599000</td>\n      <td>7.612000</td>\n      <td>7.588000</td>\n      <td>7.568000</td>\n      <td>7.553000</td>\n      <td>7.537000</td>\n      <td>7.513000</td>\n      <td>7.517000</td>\n      <td>7.519000</td>\n      <td>7.526000</td>\n      <td>7.531000</td>\n      <td>7.533000</td>\n      <td>7.565000</td>\n      <td>7.606000</td>\n      <td>7.665000</td>\n      <td>7.719000</td>\n      <td>7.717000</td>\n      <td>7.712000</td>\n      <td>7.709000</td>\n      <td>7.667000</td>\n      <td>7.642000</td>\n      <td>7.599000</td>\n      <td>7.534000</td>\n      <td>7.446000</td>\n      <td>7.339000</td>\n      <td>7.220000</td>\n      <td>7.069000</td>\n      <td>6.905000</td>\n      <td>6.722000</td>\n      <td>6.530000</td>\n      <td>6.376000</td>\n      <td>6.235000</td>\n      <td>6.099000</td>\n      <td>5.958000</td>\n      <td>5.830000</td>\n      <td>5.69600</td>\n      <td>5.560000</td>\n      <td>5.405000</td>\n      <td>5.262000</td>\n      <td>5.129000</td>\n      <td>5.002000</td>\n      <td>4.870000</td>\n      <td>4.750000</td>\n      <td>4.643000</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Africa Western and Central</td>\n      <td>AFW</td>\n      <td>Fertility rate, total (births per woman)</td>\n      <td>SP.DYN.TFRT.IN</td>\n      <td>6.458448</td>\n      <td>6.471518</td>\n      <td>6.491826</td>\n      <td>6.506088</td>\n      <td>6.525355</td>\n      <td>6.541102</td>\n      <td>6.564967</td>\n      <td>6.589806</td>\n      <td>6.612775</td>\n      <td>6.635181</td>\n      <td>6.657122</td>\n      <td>6.697724</td>\n      <td>6.733536</td>\n      <td>6.764288</td>\n      <td>6.803394</td>\n      <td>6.840536</td>\n      <td>6.861314</td>\n      <td>6.896182</td>\n      <td>6.923034</td>\n      <td>6.914118</td>\n      <td>6.896995</td>\n      <td>6.880294</td>\n      <td>6.855267</td>\n      <td>6.830516</td>\n      <td>6.780680</td>\n      <td>6.726142</td>\n      <td>6.683321</td>\n      <td>6.636463</td>\n      <td>6.599015</td>\n      <td>6.565149</td>\n      <td>6.518278</td>\n      <td>6.470556</td>\n      <td>6.418304</td>\n      <td>6.362464</td>\n      <td>6.296237</td>\n      <td>6.235698</td>\n      <td>6.170299</td>\n      <td>6.101633</td>\n      <td>6.043931</td>\n      <td>6.029579</td>\n      <td>6.023179</td>\n      <td>5.995955</td>\n      <td>5.967267</td>\n      <td>5.931999</td>\n      <td>5.887567</td>\n      <td>5.864604</td>\n      <td>5.845380</td>\n      <td>5.815814</td>\n      <td>5.788525</td>\n      <td>5.749043</td>\n      <td>5.699552</td>\n      <td>5.645672</td>\n      <td>5.580892</td>\n      <td>5.50635</td>\n      <td>5.437493</td>\n      <td>5.385059</td>\n      <td>5.328709</td>\n      <td>5.255345</td>\n      <td>5.186319</td>\n      <td>5.118932</td>\n      <td>5.049329</td>\n      <td>4.978662</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Angola</td>\n      <td>AGO</td>\n      <td>Fertility rate, total (births per woman)</td>\n      <td>SP.DYN.TFRT.IN</td>\n      <td>6.708000</td>\n      <td>6.790000</td>\n      <td>6.872000</td>\n      <td>6.954000</td>\n      <td>7.036000</td>\n      <td>7.116000</td>\n      <td>7.194000</td>\n      <td>7.267000</td>\n      <td>7.332000</td>\n      <td>7.388000</td>\n      <td>7.434000</td>\n      <td>7.467000</td>\n      <td>7.488000</td>\n      <td>7.498000</td>\n      <td>7.500000</td>\n      <td>7.494000</td>\n      <td>7.485000</td>\n      <td>7.475000</td>\n      <td>7.467000</td>\n      <td>7.461000</td>\n      <td>7.459000</td>\n      <td>7.459000</td>\n      <td>7.461000</td>\n      <td>7.462000</td>\n      <td>7.459000</td>\n      <td>7.451000</td>\n      <td>7.435000</td>\n      <td>7.409000</td>\n      <td>7.373000</td>\n      <td>7.328000</td>\n      <td>7.272000</td>\n      <td>7.208000</td>\n      <td>7.138000</td>\n      <td>7.065000</td>\n      <td>6.990000</td>\n      <td>6.918000</td>\n      <td>6.851000</td>\n      <td>6.789000</td>\n      <td>6.732000</td>\n      <td>6.683000</td>\n      <td>6.639000</td>\n      <td>6.601000</td>\n      <td>6.567000</td>\n      <td>6.533000</td>\n      <td>6.499000</td>\n      <td>6.461000</td>\n      <td>6.419000</td>\n      <td>6.372000</td>\n      <td>6.320000</td>\n      <td>6.260000</td>\n      <td>6.194000</td>\n      <td>6.120000</td>\n      <td>6.039000</td>\n      <td>5.95300</td>\n      <td>5.864000</td>\n      <td>5.774000</td>\n      <td>5.686000</td>\n      <td>5.600000</td>\n      <td>5.519000</td>\n      <td>5.442000</td>\n      <td>5.371000</td>\n      <td>5.304000</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pyspark.pandas as ps \n",
    "\n",
    "df = ps.read_csv(\"/FileStore/tables/fertility.csv/\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e9b61e26-1ecf-4666-878c-e2ffcc874409",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"/FileStore/tables/fertility_saved.csv/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "841de3ec-13c2-4e4f-b9be-0921d7b14fd1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[4]: [FileInfo(path='dbfs:/FileStore/tables/aula_1/', name='aula_1/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/FileStore/tables/fertility.csv', name='fertility.csv', size=180661, modificationTime=1710975891000),\n FileInfo(path='dbfs:/FileStore/tables/fertility_saved.csv/', name='fertility_saved.csv/', size=0, modificationTime=0)]"
     ]
    }
   ],
   "source": [
    "dbutils.fs.ls(\"/FileStore/tables/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd4181cc-b08a-4716-b8ba-7db3da348e78",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th><th>modificationTime</th></tr></thead><tbody><tr><td>dbfs:/FileStore/tables/fertility_saved.csv/_SUCCESS</td><td>_SUCCESS</td><td>0</td><td>1711144640000</td></tr><tr><td>dbfs:/FileStore/tables/fertility_saved.csv/_committed_4309657522247187872</td><td>_committed_4309657522247187872</td><td>208</td><td>1711144639000</td></tr><tr><td>dbfs:/FileStore/tables/fertility_saved.csv/_committed_7008037542647675309</td><td>_committed_7008037542647675309</td><td>111</td><td>1710978863000</td></tr><tr><td>dbfs:/FileStore/tables/fertility_saved.csv/_committed_vacuum3927824794071042249</td><td>_committed_vacuum3927824794071042249</td><td>96</td><td>1711144641000</td></tr><tr><td>dbfs:/FileStore/tables/fertility_saved.csv/_started_4309657522247187872</td><td>_started_4309657522247187872</td><td>0</td><td>1711144638000</td></tr><tr><td>dbfs:/FileStore/tables/fertility_saved.csv/part-00000-tid-4309657522247187872-63f87927-1ace-456c-8468-bcf0d7d9637d-3-1-c000.csv</td><td>part-00000-tid-4309657522247187872-63f87927-1ace-456c-8468-bcf0d7d9637d-3-1-c000.csv</td><td>145254</td><td>1711144639000</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "dbfs:/FileStore/tables/fertility_saved.csv/_SUCCESS",
         "_SUCCESS",
         0,
         1711144640000
        ],
        [
         "dbfs:/FileStore/tables/fertility_saved.csv/_committed_4309657522247187872",
         "_committed_4309657522247187872",
         208,
         1711144639000
        ],
        [
         "dbfs:/FileStore/tables/fertility_saved.csv/_committed_7008037542647675309",
         "_committed_7008037542647675309",
         111,
         1710978863000
        ],
        [
         "dbfs:/FileStore/tables/fertility_saved.csv/_committed_vacuum3927824794071042249",
         "_committed_vacuum3927824794071042249",
         96,
         1711144641000
        ],
        [
         "dbfs:/FileStore/tables/fertility_saved.csv/_started_4309657522247187872",
         "_started_4309657522247187872",
         0,
         1711144638000
        ],
        [
         "dbfs:/FileStore/tables/fertility_saved.csv/part-00000-tid-4309657522247187872-63f87927-1ace-456c-8468-bcf0d7d9637d-3-1-c000.csv",
         "part-00000-tid-4309657522247187872-63f87927-1ace-456c-8468-bcf0d7d9637d-3-1-c000.csv",
         145254,
         1711144639000
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "path",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "size",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "modificationTime",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(dbutils.fs.ls(\"/FileStore/tables/fertility_saved.csv/\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "855758e9-eab8-4bb4-8195-ce734d0b6777",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## [Avaliação anônima](https://forms.gle/tShxhxNYhvi6ZmQm8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "45e4a2db-dccf-40d2-9cd1-7ceb905aa509",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Material de Aprofundamento\n",
    "\n",
    "- [Doc pyspark.pandas](https://spark.apache.org/docs/latest/api/python/reference/pyspark.pandas/api/pyspark.pandas.DataFrame.spark.coalesce.html)\n",
    "- [DBFS](https://docs.databricks.com/en/dbfs/index.html)\n",
    "- [Hadook]"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": -1,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "1 - Databricks + Spark",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
